# -*- coding: utf-8 -*-
"""mlexp03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VbqzrgnmQPldh0OdPzYfY7vXF87cnCwQ
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from google.colab import files
 
 
uploaded = files.upload()

df = pd.read_csv('adult.csv')
df.head()

df_missing = (df=='?').sum()
df_missing

df = df[df['workclass'] !='?']
X = df.drop('income', axis=1)
Y = df['income']

X

from sklearn import preprocessing
df_categorical = df.select_dtypes(include=['object'])
df_categorical.head()

le = preprocessing.LabelEncoder()
df_categorical = df_categorical.apply(le.fit_transform)
df_categorical.head()

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=42)
ros.fit(X, Y)
X_resampled, Y_resampled = ros.fit_resample(X, Y)

from sklearn.model_selection import train_test_split

# Splitting the data into train and test
X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=99)

from sklearn.preprocessing import LabelEncoder
for col in df.columns:
    if df[col].dtypes == 'object':
        encoder = LabelEncoder()
        df[col] = encoder.fit_transform(df[col])

X = df.drop('income', axis=1)
Y = df['income']

from sklearn.tree import DecisionTreeClassifier

# Fitting the decision tree with default hyperparameters, apart from
# max_depth which is 5 so that we can plot and read the tree.
dt_default = DecisionTreeClassifier(max_depth=5)
dt_default.fit(X_train,y_train)

from sklearn.metrics import classification_report,confusion_matrix,accuracy_score

y_pred_default = dt_default.predict(X_test)
print(classification_report(y_test,y_pred_default))

print(confusion_matrix(y_test,y_pred_default))
print(accuracy_score(y_test,y_pred_default))